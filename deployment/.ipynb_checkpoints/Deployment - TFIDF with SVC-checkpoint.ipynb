{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plagiarism Detection Model\n",
    "\n",
    "* Upload data to S3\n",
    "* Define skelarn estimator\n",
    "* Training script\n",
    "* Train estimator\n",
    "* Deploy model\n",
    "* Evaluate deployed classifier - check results match experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sys path to access scripts\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# aws\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# custom scripts\n",
    "import scripts.evaluator as evaluator\n",
    "import scripts.config as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phrase = pd.read_csv(config.FINANCIAL_PHRASE_BANK)\n",
    "df_domain_dict = pd.read_csv(config.DOMAIN_DICTIONARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_phrase['text'], \n",
    "                                                    df_phrase['sentiment'], \n",
    "                                                    test_size=config.TEST_SIZE, \n",
    "                                                    random_state=config.RANDOM_STATE)\n",
    "\n",
    "df_train = pd.concat([y_train, X_train], axis=1)\n",
    "df_test = pd.concat([y_test, X_test], axis=1)\n",
    "\n",
    "df_train.to_csv(config.DP_DATASETS_LOC+'dp1_train.csv', index=False)\n",
    "df_test.to_csv(config.DP_DATASETS_LOC+'dp1_test.csv', index=False)\n",
    "df_domain_dict.to_csv(config.DP_DATASETS_LOC+'dp1_vocab.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Â DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check upload\n",
    "train_data = pd.read_csv(config.DP_DATASETS_LOC+'dp1_train.csv')\n",
    "test_data =  pd.read_csv(config.DP_DATASETS_LOC+'dp1_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(df_domain_dict.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_data.sentiment\n",
    "train_x = train_data.text\n",
    "test_x = test_data.text\n",
    "test_y = test_data.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,...ax_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "pipe = Pipeline([('tfidf', TfidfVectorizer(vocabulary=vocab, ngram_range=(1,2))),\n",
    "             ('model', LinearSVC())])\n",
    "\n",
    "pipe.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_preds = pipe.predict(test_x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7761506276150628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Second: calculate the test accuracy\n",
    "accuracy = accuracy_score(test_y, test_y_preds)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "financial_sentiment/data/dp1_test.csv\n",
      "financial_sentiment/data/dp1_train.csv\n",
      "financial_sentiment/data/dp1_vocab.csv\n",
      "financial_sentiment/data/vocab.csv\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = config.DP_DATASETS_LOC\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'financial_sentiment'\n",
    "\n",
    "# upload all data to S3\n",
    "data = sagemaker_session.upload_data(path=data_dir,\n",
    "                                     bucket=bucket,\n",
    "                                     key_prefix=prefix+'/data')\n",
    "\n",
    "# confirm that data is in S3 bucket\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Scikit-learn estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '/home/ec2-user/SageMaker/financial_headline_sentiment/deployment/source_sklearn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "# your import and estimator code, here\n",
    "\n",
    "output_path = 's3://{}/{}/{}'.format(bucket, prefix, 'model')\n",
    "\n",
    "estimator = SKLearn(entry_point='train.py', \n",
    "                    framework_version='0.20.0', \n",
    "                    source_dir=source, \n",
    "                    role=role,\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.c4.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the estimator\n",
    "\n",
    "Train estimator on the training data stored in S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01 11:22:48 Starting - Starting the training job......\n",
      "2020-06-01 11:23:19 Starting - Launching requested ML instances.........\n",
      "2020-06-01 11:24:52 Starting - Preparing the instances for training...\n",
      "2020-06-01 11:25:32 Downloading - Downloading input data...\n",
      "2020-06-01 11:26:15 Training - Training image download completed. Training in progress.\n",
      "2020-06-01 11:26:15 Uploading - Uploading generated training model\u001b[34m2020-06-01 11:26:10,065 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-06-01 11:26:10,067 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-01 11:26:10,077 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-06-01 11:26:10,330 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-06-01 11:26:10,331 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-06-01 11:26:10,331 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-06-01 11:26:10,331 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\n",
      "  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=6416 sha256=87c4acbf860a2de562afb8d2c8dfe66cb704ab879b0ad9f524b702461096ae2b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-oigcxrhq/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34m2020-06-01 11:26:11,610 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-06-01 11:26:11,622 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2020-06-01-11-22-48-208\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-2-697465252625/sagemaker-scikit-learn-2020-06-01-11-22-48-208/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-2-697465252625/sagemaker-scikit-learn-2020-06-01-11-22-48-208/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-06-01-11-22-48-208\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-2-697465252625/sagemaker-scikit-learn-2020-06-01-11-22-48-208/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python -m train\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\u001b[0m\n",
      "\u001b[34m2020-06-01 11:26:13,092 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-06-01 11:26:21 Completed - Training job completed\n",
      "Training seconds: 49\n",
      "Billable seconds: 49\n",
      "CPU times: user 515 ms, sys: 21.7 ms, total: 537 ms\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'train':data})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy trained model\n",
    "\n",
    "After training, deploy your model to create a `predictor`. If you're using a PyTorch model, you'll need to create a trained `PyTorchModel` that accepts the trained `<model>.model_data` as an input parameter and points to the provided `source_pytorch/predict.py` file as an entry point. \n",
    "\n",
    "To deploy a trained model, you'll use `<model>.deploy`, which takes in two arguments:\n",
    "* **initial_instance_count**: The number of deployed instances (1).\n",
    "* **instance_type**: The type of SageMaker instance for deployment.\n",
    "\n",
    "Note: If you run into an instance error, it may be because you chose the wrong training or deployment instance_type. It may help to refer to your previous exercise code to see which types of instances we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!CPU times: user 227 ms, sys: 14.8 ms, total: 242 ms\n",
      "Wall time: 6min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "predictor = estimator.deploy(initial_instance_count=1, \n",
    "                             instance_type='ml.t2.medium')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint Name For Lambda Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-scikit-learn-2020-06-01-11-22-48-208'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format\n",
    "\n",
    "https://docs.python.org/3/library/json.html\n",
    "https://medium.com/weareservian/machine-learning-on-aws-sagemaker-53e1a5e218d9\n",
    "https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#deploy-a-scikit-learn-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(os.path.join(data_dir, \"dp1_test.csv\"))\n",
    "\n",
    "# Labels are in the first column\n",
    "test_y = test_data.sentiment\n",
    "test_x = test_data.text\n",
    "\n",
    "# format data\n",
    "data = {'data': list(test_x)}\n",
    "data_string = json.dumps(data)\n",
    "data_encoded = data_string.encode('UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# The SageMaker runtime is what allows us to invoke the endpoint that we've created.\n",
    "runtime = boto3.Session().client('sagemaker-runtime')\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "# SageMaker runtime to invoke our endpoint, sending the headline we were given\n",
    "response = runtime.invoke_endpoint(EndpointName = 'sagemaker-scikit-learn-2020-06-01-11-22-48-208', # endpoint of estimator\n",
    "                                   ContentType = 'text/csv', # data format\n",
    "                                   Body = data_encoded)  # the headline\n",
    "\n",
    "# The response is an HTTP response whose body contains the result of our inference\n",
    "result = response['Body'].read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Evaluate Model\n",
    "\n",
    "Once your model is deployed, you can see how it performs when applied to our test data.\n",
    "\n",
    "The provided cell below, reads in the test data, assuming it is stored locally in `data_dir` and named `test.csv`. The labels and features are extracted from the `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_preds = json.loads(result)['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7761506276150628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Second: calculate the test accuracy\n",
    "accuracy = accuracy_score(test_y, test_y_preds)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for Lambda Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': ['the sale , which will result in a gain of some eur 60 million in the second quarter of 2010 for oriola-kd , supports the finnish company s strategy to focus on pharmaceutical wholesale and retail operations',\n",
       "  'scanfil expects net_sales in 2008 to remain at the 2007 level']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# format data\n",
    "data = {'data': list(test_x)[0:2]}\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## EXERCISE: Clean up Resources\n",
    "\n",
    "After you're done evaluating your model, **delete your model endpoint**. You can do this with a call to `.delete_endpoint()`. You need to show, in this notebook, that the endpoint was deleted. Any other resources, you may delete from the AWS console, and you will find more instructions on cleaning up all your resources, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and fill in the line below!\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting S3 bucket\n",
    "\n",
    "When you are *completely* done with training and testing models, you can also delete your entire S3 bucket. If you do this before you are done training your model, you'll have to recreate your S3 bucket and upload your training data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': 'D9DFC25E7CA62C32',\n",
       "   'HostId': 'EWcOd8DLhVxS4Na+Wux/lJnMMyDm/+ia/sMnwKRabQp8uPPyvbQ9jOWWxUz1uJ7lt51+zzjBHj0=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'EWcOd8DLhVxS4Na+Wux/lJnMMyDm/+ia/sMnwKRabQp8uPPyvbQ9jOWWxUz1uJ7lt51+zzjBHj0=',\n",
       "    'x-amz-request-id': 'D9DFC25E7CA62C32',\n",
       "    'date': 'Sun, 31 May 2020 18:48:48 GMT',\n",
       "    'connection': 'close',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'financial_sentiment/data/dp1_train.csv'},\n",
       "   {'Key': 'financial_sentiment/model/sagemaker-scikit-learn-2020-05-31-07-53-37-211/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'financial_sentiment/model/sagemaker-scikit-learn-2020-05-31-07-53-37-211/output/model.tar.gz'},\n",
       "   {'Key': 'financial_sentiment/data/vocab.csv'},\n",
       "   {'Key': 'financial_sentiment/data/dp1_test.csv'},\n",
       "   {'Key': 'sagemaker-scikit-learn-2020-05-31-07-53-37-211/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'financial_sentiment/data/dp1_vocab.csv'}]}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleting bucket, uncomment lines below\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
