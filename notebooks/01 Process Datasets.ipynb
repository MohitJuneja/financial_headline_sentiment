{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Datasets\n",
    "\n",
    "To build our sentiment analyser(s) we will be using two core datasets:\n",
    "* Financial phrase bank: https://www.researchgate.net/publication/251231364_FinancialPhraseBank-v10/link/0c96051eee4fb1d56e000000/download\n",
    "* Domain specific dictionary: provided on request by Srikumar Krishnamoorthy the author of Sentiment Analysis of Financial News Articles using Performance Indicators, 2017.\n",
    "\n",
    "The purpose of this notebook is to:\n",
    "1. download required datasets to the notebook instance.\n",
    "2. restructure them to a tabular format. \n",
    "3. save resulting format to csv so they can be used throughout the project.\n",
    "\n",
    "<b>NOTE:</b> No further analysis takes place in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "\n",
    "# set sys path to access scripts\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "\n",
    "# imports\n",
    "import scripts.config as config\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data & Process Financial Phrase Bank\n",
    "\n",
    "The dataset contains four text files. Each file is distinguised by a confidence percentage, the % of annotators that agreed on the sentiment. For example in the 'Sentences_66Agree.txt'.txt at least 66% of the annotators had to agree on the underlying sentiment. The word at least here is important. The dataset 'Sentences_50Agree.txt' contains all of the examples where 66%, 75% and 100% or more agree (the examples in the other three text files) as well as all the examples where 55-66% of the annotators agreed.\n",
    "\n",
    "For this reason, we will only use the 50% or more agree dataset. \n",
    "\n",
    "That being said, we can import all 4 datasets to check there are no discrepancies in the overlaps. That is to say the examples where 75% of the annotators agree in the 50% or more dataset should match exactly with 75% or more dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset directory\n",
    "dataset_dir = config.DATASETS_LOC\n",
    "\n",
    "# financial phrase bank dataset directory\n",
    "phrase_dir = dataset_dir + '/FinancialPhraseBank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text files and corresponding confidences\n",
    "conf_mapping = {'Sentences_AllAgree.txt':1, 'Sentences_75Agree.txt':0.75, \n",
    "                'Sentences_66Agree.txt':0.66, 'Sentences_50Agree.txt':0.5}\n",
    "phrase_files = list(conf_mapping.keys())\n",
    "\n",
    "# stop words\n",
    "class_mapping = {'.@positive': 'positive', '.@neutral': 'neutral', '.@negative': 'negative'}\n",
    "stop_words = list(class_mapping.keys())\n",
    "\n",
    "# define empty dict to store data\n",
    "dict_phrasebank = {'sentiment':[], 'text':[], 'confidence':[]}\n",
    "\n",
    "# initiate empty text\n",
    "text = ''\n",
    "\n",
    "# iterate over each text file\n",
    "for phrase_file in phrase_files:\n",
    "    \n",
    "    # get confidence score relating to text file\n",
    "    confidence = conf_mapping[phrase_file]\n",
    "    \n",
    "    # read text file word by word of text file\n",
    "    with open(phrase_dir + '/' + phrase_file,'r',encoding='\"ISO-8859-1\"') as f:\n",
    "        \n",
    "        # iterate over lines in file\n",
    "        for line in f:\n",
    "            \n",
    "            # iterate over words in line\n",
    "            for word in line.split():\n",
    "                \n",
    "                # when stop word is reached\n",
    "                if word in stop_words:\n",
    "                    \n",
    "                    text = text.lower()\n",
    "                    \n",
    "                    # update dictionary to store sentiment, text and confidence\n",
    "                    sentiment = class_mapping[word]\n",
    "                    dict_phrasebank['sentiment'].append(sentiment)\n",
    "                    dict_phrasebank['text'].append(text)\n",
    "                    dict_phrasebank['confidence'].append(confidence)\n",
    "                    \n",
    "                    # reset text for next phrase\n",
    "                    text = ''\n",
    "                \n",
    "                # otherwise add word to body of text \n",
    "                else:\n",
    "                    text = text + ' ' + word\n",
    "\n",
    "# create dataframe \n",
    "df_phrasebook = pd.DataFrame(dict_phrasebank)\n",
    "\n",
    "# remove duplicate data to save space\n",
    "#!rm /home/ec2-user/SageMaker/mle-capstone/datasets/FinancialPhraseBank/Sentences_50Agree.txt\n",
    "#!rm /home/ec2-user/SageMaker/mle-capstone/datasets/FinancialPhraseBank/Sentences_66Agree.txt\n",
    "#!rm /home/ec2-user/SageMaker/mle-capstone/datasets/FinancialPhraseBank/Sentences_75Agree.txt\n",
    "#!rm /home/ec2-user/SageMaker/mle-capstone/datasets/FinancialPhraseBank/Sentences_AllAgree.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(df_phrasebook):\n",
    "    # create sets\n",
    "    set_100pct = set(df_phrasebook[df_phrasebook['confidence']==1.0]['text'])\n",
    "    set_75pct = set(df_phrasebook[df_phrasebook['confidence']==0.75]['text'])\n",
    "    set_66pct = set(df_phrasebook[df_phrasebook['confidence']==0.66]['text'])\n",
    "    set_50pct = set(df_phrasebook[df_phrasebook['confidence']==0.50]['text'])\n",
    "\n",
    "    # between 50% and 66% confidence\n",
    "    conf_set_1 = set_50pct - set_66pct - set_75pct - set_100pct\n",
    "    conf_1 = round((0.5+0.66)/2,2)\n",
    "\n",
    "    # between 66% and 75% confidence\n",
    "    conf_set_2 = set_66pct - set_75pct - set_100pct\n",
    "    conf_2 = round((0.66+0.75)/2,2)\n",
    "\n",
    "    # between 75% and 100% confidence\n",
    "    conf_set_3 = set_75pct - set_100pct\n",
    "    conf_3 = round((0.75+1)/2,2)\n",
    "\n",
    "    # 100% confidence\n",
    "    conf_set_4 = set_100pct\n",
    "    conf_4 = 1.0\n",
    "\n",
    "    # create dataframe of unique values\n",
    "    df_phrasebook_new = df_phrasebook[['sentiment','text']]\n",
    "    df_phrasebook_new = df_phrasebook_new.drop_duplicates(['sentiment','text'])\n",
    "    row_count = df_phrasebook_new.shape[0]\n",
    "    \n",
    "    def set_conf_levels(text):\n",
    "        if text in conf_set_1:\n",
    "            return conf_1\n",
    "        elif text in conf_set_2:\n",
    "            return conf_2\n",
    "        elif text in conf_set_3:\n",
    "            return conf_3\n",
    "        elif text in conf_set_4:\n",
    "            return conf_4\n",
    "   \n",
    "    df_phrasebook_new['confidence'] = df_phrasebook_new['text'].apply(set_conf_levels)\n",
    "    \n",
    "    print('Expected row count condition met: ' + str(len(conf_set_4) + len(conf_set_3) + \n",
    "                                                     len(conf_set_2) + len(conf_set_1) == row_count))\n",
    "    \n",
    "    return df_phrasebook_new   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected row count condition met: False\n"
     ]
    }
   ],
   "source": [
    "df_phrasebook_new = create_df(df_phrasebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9743      telecomworldwire-7 april 2006-tj group plc se...\n",
       "10433     the group 's business is balanced by its broa...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for duplicated text -- there should be none unless there are duplicated texts with different sentiments\n",
    "df_phrasebook_new[df_phrasebook_new['text'].duplicated()]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5626</th>\n",
       "      <td>positive</td>\n",
       "      <td>telecomworldwire-7 april 2006-tj group plc se...</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6234</th>\n",
       "      <td>positive</td>\n",
       "      <td>the group 's business is balanced by its broa...</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9743</th>\n",
       "      <td>neutral</td>\n",
       "      <td>telecomworldwire-7 april 2006-tj group plc se...</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>positive</td>\n",
       "      <td>telecomworldwire-7 april 2006-tj group plc se...</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10432</th>\n",
       "      <td>positive</td>\n",
       "      <td>the group 's business is balanced by its broa...</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10433</th>\n",
       "      <td>neutral</td>\n",
       "      <td>the group 's business is balanced by its broa...</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text  confidence\n",
       "5626   positive   telecomworldwire-7 april 2006-tj group plc se...        0.66\n",
       "6234   positive   the group 's business is balanced by its broa...        0.66\n",
       "9743    neutral   telecomworldwire-7 april 2006-tj group plc se...        0.50\n",
       "9744   positive   telecomworldwire-7 april 2006-tj group plc se...        0.50\n",
       "10432  positive   the group 's business is balanced by its broa...        0.50\n",
       "10433   neutral   the group 's business is balanced by its broa...        0.50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# duplicated texts\n",
    "duplicated_1 = df_phrasebook_new[df_phrasebook_new['text'].duplicated()]['text'][9743]\n",
    "duplicated_2 = df_phrasebook_new[df_phrasebook_new['text'].duplicated()]['text'][10433]\n",
    "\n",
    "# see duplicated texts in original dataframes\n",
    "df_phrasebook[(df_phrasebook['text']==duplicated_1) | (df_phrasebook['text']==duplicated_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected row count condition met: True\n"
     ]
    }
   ],
   "source": [
    "# drop ambigious examples\n",
    "drop_indicies = [9743,9744,10432,10433]\n",
    "df_phrasebook = df_phrasebook.drop(index=drop_indicies)\n",
    "df_phrasebook_new = create_df(df_phrasebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4778, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>according to gran , the company has no plans ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>for the last quarter of 2010 , componenta 's ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>in the third quarter of 2010 , net sales incr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>operating profit rose to eur 13.1 mn from eur...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>operating profit totalled eur 21.1 mn , up fr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text  confidence\n",
       "0   neutral   according to gran , the company has no plans ...         1.0\n",
       "1  positive   for the last quarter of 2010 , componenta 's ...         1.0\n",
       "2  positive   in the third quarter of 2010 , net sales incr...         1.0\n",
       "3  positive   operating profit rose to eur 13.1 mn from eur...         1.0\n",
       "4  positive   operating profit totalled eur 21.1 mn , up fr...         1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_phrasebook_new.shape)\n",
    "df_phrasebook_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe to csv\n",
    "df_phrasebook_new.to_csv(config.FINANCIAL_PHRASE_BANK, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Dictionaries\n",
    "\n",
    "Dictionaries \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_DIRECTIONALITY = '/home/ec2-user/SageMaker/financial_headline_sentiment/datasets/FinancialDictionary/directionality.json'\n",
    "DICT_LAGGING = '/home/ec2-user/SageMaker/financial_headline_sentiment/datasets/FinancialDictionary/lagging.json'\n",
    "DICT_LEADING= '/home/ec2-user/SageMaker/financial_headline_sentiment/datasets/FinancialDictionary/leading.json'\n",
    "DICT_NEGATIVE = '/home/ec2-user/SageMaker/financial_headline_sentiment/datasets/FinancialDictionary/negative.json'\n",
    "DICT_POSITIVE = '/home/ec2-user/SageMaker/financial_headline_sentiment/datasets/FinancialDictionary/positive.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dictionary(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load json dictionaries to file\n",
    "leading = load_dictionary(DICT_LEADING)\n",
    "lagging = load_dictionary(DICT_LAGGING)\n",
    "directionality = load_dictionary(DICT_DIRECTIONALITY)\n",
    "positive = load_dictionary(DICT_POSITIVE)\n",
    "negative = load_dictionary(DICT_NEGATIVE)\n",
    "\n",
    "dictionaries = [leading, lagging, directionality, positive, negative]\n",
    "\n",
    "# check for duplicates\n",
    "total_duplicates = 0\n",
    "domain_dict = dict()\n",
    "for dictinoary in dictionaries:\n",
    "    domain_dict.update(dictinoary)\n",
    "    total_duplicates += pd.DataFrame(list(dictinoary.keys())).duplicated().sum()\n",
    "total_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe from json objects\n",
    "df_domain_dict = pd.DataFrame(np.array([list(domain_dict.keys()), list(domain_dict.values())]).transpose(), columns=['word','type'])\n",
    "\n",
    "# rename positive and negative sentiment words - to not confuse with positive and negative sentiment classes\n",
    "df_domain_dict.replace('positive', 'pos', inplace=True)\n",
    "df_domain_dict.replace('negative', 'neg', inplace=True)\n",
    "\n",
    "# check for duplicates\n",
    "df_domain_dict.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>operations</td>\n",
       "      <td>leading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new service</td>\n",
       "      <td>leading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stores</td>\n",
       "      <td>leading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deal</td>\n",
       "      <td>leading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passenger</td>\n",
       "      <td>leading</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word     type\n",
       "0   operations  leading\n",
       "1  new service  leading\n",
       "2       stores  leading\n",
       "3         deal  leading\n",
       "4    passenger  leading"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visual check\n",
    "df_domain_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary\n",
    "df_domain_dict.to_csv(config.DOMAIN_DICTIONARY, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
